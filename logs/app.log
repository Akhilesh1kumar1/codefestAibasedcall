{"timestamp":"2025-02-06 09:32:49","level":"INFO","message":"HV000001: Hibernate Validator 8.0.1.Final","className":"org.hibernate.validator.internal.util.Version"}
{"timestamp":"2025-02-06 09:32:49","level":"INFO","message":"Starting CapitalApplication using Java 17.0.13 with PID 215915 (/home/akhileshkumar/IdeaProjects/capitalV2/build/classes/java/main started by akhileshkumar in /home/akhileshkumar/IdeaProjects/capitalV2)","className":"com.sr.capital.CapitalApplication"}
{"timestamp":"2025-02-06 09:32:49","level":"INFO","message":"The following 1 profile is active: \"local\"","className":"com.sr.capital.CapitalApplication"}
{"timestamp":"2025-02-06 09:32:49","level":"INFO","message":"Devtools property defaults active! Set 'spring.devtools.add-properties' to 'false' to disable","className":"org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor"}
{"timestamp":"2025-02-06 09:32:49","level":"INFO","message":"For additional web related logging consider setting the 'logging.level.web' property to 'DEBUG'","className":"org.springframework.boot.devtools.env.DevToolsPropertyDefaultsPostProcessor"}
{"timestamp":"2025-02-06 09:32:49","level":"WARN","message":"Support for convention-based annotation attribute overrides is deprecated and will be removed in Spring Framework 6.1. Please annotate the following attributes in @org.springframework.retry.annotation.EnableRetry with appropriate @AliasFor declarations: [proxyTargetClass]","className":"org.springframework.core.annotation.AnnotationTypeMapping"}
{"timestamp":"2025-02-06 09:32:50","level":"INFO","message":"Multiple Spring Data modules found, entering strict repository configuration mode","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:50","level":"INFO","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:50","level":"INFO","message":"Finished Spring Data repository scanning in 255 ms. Found 28 JPA repository interfaces.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:50","level":"INFO","message":"Multiple Spring Data modules found, entering strict repository configuration mode","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:50","level":"INFO","message":"Bootstrapping Spring Data JPA repositories in DEFAULT mode.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Finished Spring Data repository scanning in 7 ms. Found 3 JPA repository interfaces.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Multiple Spring Data modules found, entering strict repository configuration mode","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.AccountTypeRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.AdharRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.BankRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.BaseCreditPartnerRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.CompanyKycRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.CompanyLoanVendorMappingRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.DirectorKycRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.EnachLinkingRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanApplicationRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanApplicationStatusRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanDisbursedRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanOfferRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.PANRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.PincodeRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.ProviderTemplateConfigRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.ProviderUrlConfigEntityRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.RSAKeysRepo; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.TaskRepo; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.TenantBankDetailsRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.UnderWritingConfigRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.UserMappingRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.UserRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.VerificationRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.WhatsAppRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.secondary.CapitalDataReportRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.secondary.CompanyWiseReportRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data MongoDB - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.secondary.TestRepository; If you want this repository to be a MongoDB repository, consider annotating your entities with one of these annotations: org.springframework.data.mongodb.core.mapping.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.mongodb.repository.MongoRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Finished Spring Data repository scanning in 146 ms. Found 38 MongoDB repository interfaces.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Multiple Spring Data modules found, entering strict repository configuration mode","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Bootstrapping Spring Data Redis repositories in DEFAULT mode.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.corpveda.repository.CorpVedaDocDetailsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.corpveda.repository.PartnerDetailsMetaDataRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.corpveda.repository.PlaceOrderRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.truthscreen.repository.GstinAggregateDataHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.truthscreen.repository.GstinAggregateDataRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.truthscreen.repository.NddAggregateDataHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.truthscreen.repository.NddAggregateDataRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.truthscreen.repository.TruthScreenDocDetailsHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.external.truthscreen.repository.TruthScreenDocDetailsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.redis.repository.mongo.RedisEventTrackingRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.redis.repository.mongo.RedisReferenceIdTrackingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.BureauInitiateModelRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.CreditPartnerConfigRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.CrifConsentDetailsRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.CrifReportRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.CrifUserModelRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.DisbursmentMongoRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.ErrorLogsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.FeatureDetailRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.FileUploadDataRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.GstCompeteDocHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.GstCompleteDocDetailsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.ItrDocDetailsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.ItrDocHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.KycDocDetailsHistoryRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.KycDocDetailsRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.KycVerifiedDetailsRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.LeadGenerationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.LeadHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.LoanMetaDataRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.PartnerLeadDetailsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.SanctionRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.UnderWritingConfigHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.WebhookHistoryRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.WebhookRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.los.FormProgressRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.los.LosStatusEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.mongo.los.LosUserRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.AccountTypeRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.AdharRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.BankRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.BaseCreditPartnerRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.CompanyKycRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.CompanyLoanVendorMappingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.DirectorKycRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.EnachLinkingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanApplicationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanApplicationStatusRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanDisbursedRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.LoanOfferRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.PANRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.PincodeRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.ProviderTemplateConfigRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.ProviderUrlConfigEntityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.RSAKeysRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.TaskRepo; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.TenantBankDetailsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.UnderWritingConfigRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.UserMappingRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.UserRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.VerificationRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.primary.WhatsAppRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.secondary.CapitalDataReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.secondary.CompanyWiseReportRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.sr.capital.repository.secondary.TestRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository","className":"org.springframework.data.repository.config.RepositoryConfigurationExtensionSupport"}
{"timestamp":"2025-02-06 09:32:51","level":"INFO","message":"Finished Spring Data repository scanning in 51 ms. Found 0 Redis repository interfaces.","className":"org.springframework.data.repository.config.RepositoryConfigurationDelegate"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Tomcat initialized with port(s): 8080 (http)","className":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Initializing ProtocolHandler [\"http-nio-8080\"]","className":"org.apache.coyote.http11.Http11NioProtocol"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Starting service [Tomcat]","className":"org.apache.catalina.core.StandardService"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Starting Servlet engine: [Apache Tomcat/10.1.12]","className":"org.apache.catalina.core.StandardEngine"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Initializing Spring embedded WebApplicationContext","className":"org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Root WebApplicationContext: initialization completed in 3009 ms","className":"org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext"}
{"timestamp":"2025-02-06 09:32:52","level":"INFO","message":"Redisson 3.23.3","className":"org.redisson.Version"}
{"timestamp":"2025-02-06 09:32:53","level":"INFO","message":"1 connections initialized for localhost/127.0.0.1:6379","className":"org.redisson.connection.pool.MasterPubSubConnectionPool"}
{"timestamp":"2025-02-06 09:32:53","level":"INFO","message":"10 connections initialized for localhost/127.0.0.1:6379","className":"org.redisson.connection.pool.MasterConnectionPool"}
{"timestamp":"2025-02-06 09:32:53","level":"INFO","message":"HikariPoolPrimary - Starting...","className":"com.zaxxer.hikari.HikariDataSource"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"HikariPoolPrimary - Added connection com.mysql.cj.jdbc.ConnectionImpl@36cb3779","className":"com.zaxxer.hikari.pool.HikariPool"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"HikariPoolPrimary - Start completed.","className":"com.zaxxer.hikari.HikariDataSource"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"Flyway Community Edition 9.5.1 by Redgate","className":"org.flywaydb.core.internal.license.VersionPrinter"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"See what's new here: https://flywaydb.org/documentation/learnmore/releaseNotes#9.5.1","className":"org.flywaydb.core.internal.license.VersionPrinter"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"","className":"org.flywaydb.core.internal.license.VersionPrinter"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"Database: jdbc:mysql://localhost:3306/capital (MySQL 8.0)","className":"org.flywaydb.core.internal.database.base.BaseDatabaseType"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"Successfully validated 29 migrations (execution time 00:00.052s)","className":"org.flywaydb.core.internal.command.DbValidate"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"Current version of schema `capital`: 34","className":"org.flywaydb.core.internal.command.DbMigrate"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"Schema `capital` is up to date. No migration necessary.","className":"org.flywaydb.core.internal.command.DbMigrate"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"HHH000204: Processing PersistenceUnitInfo [name: default]","className":"org.hibernate.jpa.internal.util.LogHelper"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"HHH000412: Hibernate ORM core version 6.1.7.Final","className":"org.hibernate.Version"}
{"timestamp":"2025-02-06 09:32:54","level":"INFO","message":"HHH000400: Using dialect: org.hibernate.dialect.MySQLDialect","className":"SQL dialect"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]","className":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'","className":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HikariPoolPrimary - Starting...","className":"com.zaxxer.hikari.HikariDataSource"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HikariPoolPrimary - Added connection com.mysql.cj.jdbc.ConnectionImpl@2b2b8458","className":"com.zaxxer.hikari.pool.HikariPool"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HikariPoolPrimary - Start completed.","className":"com.zaxxer.hikari.HikariDataSource"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HHH000204: Processing PersistenceUnitInfo [name: default]","className":"org.hibernate.jpa.internal.util.LogHelper"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HHH000400: Using dialect: org.hibernate.dialect.MySQLDialect","className":"SQL dialect"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]","className":"org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator"}
{"timestamp":"2025-02-06 09:32:56","level":"INFO","message":"Initialized JPA EntityManagerFactory for persistence unit 'default'","className":"org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"}
{"timestamp":"2025-02-06 09:32:57","level":"INFO","message":"MongoClient with metadata {\"driver\": {\"name\": \"mongo-java-driver|sync|spring-boot\", \"version\": \"4.8.2\"}, \"os\": {\"type\": \"Linux\", \"name\": \"Linux\", \"architecture\": \"amd64\", \"version\": \"5.15.0-130-generic\"}, \"platform\": \"Java/Ubuntu/17.0.13+11-Ubuntu-2ubuntu120.04\"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6f6a7233], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@6117214]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@734398d1], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}","className":"org.mongodb.driver.client"}
{"timestamp":"2025-02-06 09:32:57","level":"INFO","message":"Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=25, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49625567}","className":"org.mongodb.driver.cluster"}
{"timestamp":"2025-02-06 09:32:57","level":"INFO","message":"LiveReload server is running on port 35729","className":"org.springframework.boot.devtools.autoconfigure.OptionalLiveReloadServer"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"Creating kafka producer(s)","className":"com.omunify.kafka.publisher.connection.ProducerConnectionFactory"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"ProducerConfig values: \n\tacks = -1\n\tbatch.size = 16384\n\tbootstrap.servers = [localhost:9093]\n\tbuffer.memory = 33554432\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = producer-1\n\tcompression.type = none\n\tconnections.max.idle.ms = 172800000\n\tdelivery.timeout.ms = 120000\n\tenable.idempotence = false\n\tinterceptor.classes = []\n\tkey.serializer = class org.apache.kafka.common.serialization.StringSerializer\n\tlinger.ms = 0\n\tmax.block.ms = 5000\n\tmax.in.flight.requests.per.connection = 1\n\tmax.request.size = 1048576\n\tmetadata.max.age.ms = 300000\n\tmetadata.max.idle.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartitioner.adaptive.partitioning.enable = true\n\tpartitioner.availability.timeout.ms = 0\n\tpartitioner.class = null\n\tpartitioner.ignore.keys = false\n\treceive.buffer.bytes = 32768\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretries = 0\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\ttransaction.timeout.ms = 60000\n\ttransactional.id = null\n\tvalue.serializer = class org.apache.kafka.common.serialization.StringSerializer\n","className":"org.apache.kafka.clients.producer.ProducerConfig"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"Kafka version: 3.3.2","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"Kafka commitId: b66af662e61082cb","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"Kafka startTimeMs: 1738834379085","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:32:59","level":"WARN","message":"Using deprecated '-debug' fallback for parameter name resolution. Compile the affected code with '-parameters' instead or avoid its introspection: com.omunify.kafka.repository.KafkaOutboundMessageRepository","className":"org.springframework.core.LocalVariableTableParameterNameDiscoverer"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"[Producer clientId=producer-1] Cluster ID: GU-1wt33TTesg64CsA63ow","className":"org.apache.kafka.clients.Metadata"}
{"timestamp":"2025-02-06 09:32:59","level":"INFO","message":"Constructing EventHandler map","className":"com.omunify.kafka.consumer.handler.MessageHandlerFactory"}
{"timestamp":"2025-02-06 09:32:59","level":"WARN","message":"Using deprecated '-debug' fallback for parameter name resolution. Compile the affected code with '-parameters' instead or avoid its introspection: com.omunify.kafka.repository.KafkaInboundMessageRepository","className":"org.springframework.core.LocalVariableTableParameterNameDiscoverer"}
{"timestamp":"2025-02-06 09:32:59","level":"WARN","message":"Using deprecated '-debug' fallback for parameter name resolution. Compile the affected code with '-parameters' instead or avoid its introspection: com.omunify.kafka.repository.FailedGroupTraceRepository","className":"org.springframework.core.LocalVariableTableParameterNameDiscoverer"}
{"timestamp":"2025-02-06 09:33:00","level":"WARN","message":"Using deprecated '-debug' fallback for parameter name resolution. Compile the affected code with '-parameters' instead or avoid its introspection: com.omunify.kafka.repository.KafkaJpaLockRepository","className":"org.springframework.core.LocalVariableTableParameterNameDiscoverer"}
{"timestamp":"2025-02-06 09:33:00","level":"INFO","message":"Scheduling kafka producer retry","className":"com.omunify.kafka.publisher.service.RetryPublishService"}
{"timestamp":"2025-02-06 09:33:00","level":"INFO","message":"Setup done","className":"com.omunify.restutil.setup.ConfigureRestClient"}
{"timestamp":"2025-02-06 09:33:01","level":"INFO","message":"Creating S3 SDK Instance","className":"com.sr.capital.external.aws.AwsS3Client"}
{"timestamp":"2025-02-06 09:33:01","level":"WARN","message":"spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning","className":"org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration$JpaWebConfiguration"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Exposing 15 endpoint(s) beneath base path '/actuator'","className":"org.springframework.boot.actuate.endpoint.web.EndpointLinksResolver"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Starting ProtocolHandler [\"http-nio-8080\"]","className":"org.apache.coyote.http11.Http11NioProtocol"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Tomcat started on port(s): 8080 (http) with context path ''","className":"org.springframework.boot.web.embedded.tomcat.TomcatWebServer"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Started CapitalApplication in 14.343 seconds (process running for 15.258)","className":"com.sr.capital.CapitalApplication"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Inside startMainConsumerThreads method","className":"com.omunify.kafka.consumer.MessageInitiator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Validating the consumer groups config...","className":"com.omunify.kafka.consumer.util.ValidationUtil"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Starting Kafka consumer threads on bootup ...","className":"com.omunify.kafka.consumer.MessageInitiator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Starting main consumer main-consumer-thread-capital-status-update-0 for topic capital and group status-update","className":"com.omunify.kafka.consumer.MessageInitiator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Inside initiateRetryConsumers method for topic capital and consumer group status-update","className":"com.omunify.kafka.consumer.MessageInitiator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Starting retry consumer retry-consumer-thread-capital-status-update-0-1738834383623 for topic capital and group status-update","className":"com.omunify.kafka.consumer.MessageInitiator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Finished initiateRetryConsumers method for topic capital and consumer group status-update","className":"com.omunify.kafka.consumer.MessageInitiator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"ConsumerConfig values: \n\tallow.auto.create.topics = false\n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [localhost:9093]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = consumer-capital-status-update-1\n\tclient.rack = \n\tconnections.max.idle.ms = 172800000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = capital-status-update\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 1\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 10000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n","className":"org.apache.kafka.clients.consumer.ConsumerConfig"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Kafka version: 3.3.2","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Kafka commitId: b66af662e61082cb","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Kafka startTimeMs: 1738834383687","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Subscribed to topic(s): capital","className":"org.apache.kafka.clients.consumer.KafkaConsumer"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Resetting the last seen epoch of partition capital-0 to 0 since the associated topicId changed from null to CgC7wl95S2uVhj7dCYloDQ","className":"org.apache.kafka.clients.Metadata"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Cluster ID: GU-1wt33TTesg64CsA63ow","className":"org.apache.kafka.clients.Metadata"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Discovered group coordinator localhost:9093 (id: 2147482646 rack: null)","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] (Re-)joining group","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Request joining group due to: need to re-join with the given member-id: consumer-capital-status-update-1-a94f60d6-c4bd-4573-9fca-6d77e5bec417","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] (Re-)joining group","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Successfully joined group with generation Generation{generationId=63, memberId='consumer-capital-status-update-1-a94f60d6-c4bd-4573-9fca-6d77e5bec417', protocol='range'}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Finished assignment for group at generation 63: {consumer-capital-status-update-1-a94f60d6-c4bd-4573-9fca-6d77e5bec417=Assignment(partitions=[capital-0])}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Successfully synced group in generation Generation{generationId=63, memberId='consumer-capital-status-update-1-a94f60d6-c4bd-4573-9fca-6d77e5bec417', protocol='range'}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Notifying assignor about the new Assignment(partitions=[capital-0])","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Adding newly assigned partitions: capital-0","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"Assigned partitions after re-balance: [capital-0] for thread main-consumer-thread-capital-status-update-0","className":"com.omunify.kafka.consumer.service.ConsumerRebalanceListenerImpl"}
{"timestamp":"2025-02-06 09:33:03","level":"INFO","message":"[Consumer clientId=consumer-capital-status-update-1, groupId=capital-status-update] Setting offset for partition capital-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9093 (id: 1001 rack: null)], epoch=0}}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:10","level":"DEBUG","message":"delete from kafka_jpa_lock where lock_id=? and expires_at<?","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:10","level":"DEBUG","message":"insert into kafka_jpa_lock (lock_id,expires_at) values (?,?)","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:10","level":"DEBUG","message":"select * from kafka_outbound_messages m where m.sent=0 and m.retries < ? order by id ASC limit ?","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:10","level":"DEBUG","message":"delete from kafka_jpa_lock where lock_id=?","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"ConsumerConfig values: \n\tallow.auto.create.topics = false\n\tauto.commit.interval.ms = 5000\n\tauto.offset.reset = earliest\n\tbootstrap.servers = [localhost:9093]\n\tcheck.crcs = true\n\tclient.dns.lookup = use_all_dns_ips\n\tclient.id = consumer-retryGroup-capital-status-update-2\n\tclient.rack = \n\tconnections.max.idle.ms = 172800000\n\tdefault.api.timeout.ms = 60000\n\tenable.auto.commit = false\n\texclude.internal.topics = true\n\tfetch.max.bytes = 52428800\n\tfetch.max.wait.ms = 500\n\tfetch.min.bytes = 1\n\tgroup.id = retryGroup-capital-status-update\n\tgroup.instance.id = null\n\theartbeat.interval.ms = 3000\n\tinterceptor.classes = []\n\tinternal.leave.group.on.close = true\n\tinternal.throw.on.fetch.stable.offset.unsupported = false\n\tisolation.level = read_uncommitted\n\tkey.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n\tmax.partition.fetch.bytes = 1048576\n\tmax.poll.interval.ms = 300000\n\tmax.poll.records = 1\n\tmetadata.max.age.ms = 300000\n\tmetric.reporters = []\n\tmetrics.num.samples = 2\n\tmetrics.recording.level = INFO\n\tmetrics.sample.window.ms = 30000\n\tpartition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]\n\treceive.buffer.bytes = 65536\n\treconnect.backoff.max.ms = 1000\n\treconnect.backoff.ms = 50\n\trequest.timeout.ms = 30000\n\tretry.backoff.ms = 100\n\tsasl.client.callback.handler.class = null\n\tsasl.jaas.config = null\n\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n\tsasl.kerberos.min.time.before.relogin = 60000\n\tsasl.kerberos.service.name = null\n\tsasl.kerberos.ticket.renew.jitter = 0.05\n\tsasl.kerberos.ticket.renew.window.factor = 0.8\n\tsasl.login.callback.handler.class = null\n\tsasl.login.class = null\n\tsasl.login.connect.timeout.ms = null\n\tsasl.login.read.timeout.ms = null\n\tsasl.login.refresh.buffer.seconds = 300\n\tsasl.login.refresh.min.period.seconds = 60\n\tsasl.login.refresh.window.factor = 0.8\n\tsasl.login.refresh.window.jitter = 0.05\n\tsasl.login.retry.backoff.max.ms = 10000\n\tsasl.login.retry.backoff.ms = 100\n\tsasl.mechanism = GSSAPI\n\tsasl.oauthbearer.clock.skew.seconds = 30\n\tsasl.oauthbearer.expected.audience = null\n\tsasl.oauthbearer.expected.issuer = null\n\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n\tsasl.oauthbearer.jwks.endpoint.url = null\n\tsasl.oauthbearer.scope.claim.name = scope\n\tsasl.oauthbearer.sub.claim.name = sub\n\tsasl.oauthbearer.token.endpoint.url = null\n\tsecurity.protocol = PLAINTEXT\n\tsecurity.providers = null\n\tsend.buffer.bytes = 131072\n\tsession.timeout.ms = 10000\n\tsocket.connection.setup.timeout.max.ms = 30000\n\tsocket.connection.setup.timeout.ms = 10000\n\tssl.cipher.suites = null\n\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n\tssl.endpoint.identification.algorithm = https\n\tssl.engine.factory.class = null\n\tssl.key.password = null\n\tssl.keymanager.algorithm = SunX509\n\tssl.keystore.certificate.chain = null\n\tssl.keystore.key = null\n\tssl.keystore.location = null\n\tssl.keystore.password = null\n\tssl.keystore.type = JKS\n\tssl.protocol = TLSv1.3\n\tssl.provider = null\n\tssl.secure.random.implementation = null\n\tssl.trustmanager.algorithm = PKIX\n\tssl.truststore.certificates = null\n\tssl.truststore.location = null\n\tssl.truststore.password = null\n\tssl.truststore.type = JKS\n\tvalue.deserializer = class org.apache.kafka.common.serialization.StringDeserializer\n","className":"org.apache.kafka.clients.consumer.ConsumerConfig"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"Kafka version: 3.3.2","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"Kafka commitId: b66af662e61082cb","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"Kafka startTimeMs: 1738834393653","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:13","level":"DEBUG","message":"delete from kafka_jpa_lock where lock_id=? and expires_at<?","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:13","level":"DEBUG","message":"insert into kafka_jpa_lock (lock_id,expires_at) values (?,?)","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Subscribed to topic(s): capital-capital-status-update-retry","className":"org.apache.kafka.clients.consumer.KafkaConsumer"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Resetting the last seen epoch of partition capital-capital-status-update-retry-0 to 0 since the associated topicId changed from null to UQqBgGTLTcm9VTTrIdNaOw","className":"org.apache.kafka.clients.Metadata"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Cluster ID: GU-1wt33TTesg64CsA63ow","className":"org.apache.kafka.clients.Metadata"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Discovered group coordinator localhost:9093 (id: 2147482646 rack: null)","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] (Re-)joining group","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Request joining group due to: need to re-join with the given member-id: consumer-retryGroup-capital-status-update-2-fc3e75ad-a0c1-446d-8a18-84ba606936d1","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] (Re-)joining group","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Successfully joined group with generation Generation{generationId=13, memberId='consumer-retryGroup-capital-status-update-2-fc3e75ad-a0c1-446d-8a18-84ba606936d1', protocol='range'}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Finished assignment for group at generation 13: {consumer-retryGroup-capital-status-update-2-fc3e75ad-a0c1-446d-8a18-84ba606936d1=Assignment(partitions=[capital-capital-status-update-retry-0])}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Successfully synced group in generation Generation{generationId=13, memberId='consumer-retryGroup-capital-status-update-2-fc3e75ad-a0c1-446d-8a18-84ba606936d1', protocol='range'}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Notifying assignor about the new Assignment(partitions=[capital-capital-status-update-retry-0])","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Adding newly assigned partitions: capital-capital-status-update-retry-0","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"Assigned partitions after re-balance: [capital-capital-status-update-retry-0] for thread retry-consumer-thread-capital-status-update-0-1738834383623","className":"com.omunify.kafka.consumer.service.ConsumerRebalanceListenerImpl"}
{"timestamp":"2025-02-06 09:33:13","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Setting offset for partition capital-capital-status-update-retry-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[localhost:9093 (id: 1001 rack: null)], epoch=0}}","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:15","level":"INFO","message":"[retry-consumer-thread-capital-status-update-0-1738834383623] Got empty records for retry topic. Waiting for 5 secs","className":"com.omunify.kafka.consumer.thread.RetryConsumerThread"}
{"timestamp":"2025-02-06 09:33:21","level":"INFO","message":"[retry-consumer-thread-capital-status-update-0-1738834383623] Got empty records for retry topic. Waiting for 5 secs","className":"com.omunify.kafka.consumer.thread.RetryConsumerThread"}
{"timestamp":"2025-02-06 09:33:28","level":"INFO","message":"[retry-consumer-thread-capital-status-update-0-1738834383623] Got empty records for retry topic. Waiting for 5 secs","className":"com.omunify.kafka.consumer.thread.RetryConsumerThread"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"[retry-consumer-thread-capital-status-update-0-1738834383623] Retry topic waiting time for records exhausted. So retry consumer will be stopped.","className":"com.omunify.kafka.consumer.thread.RetryConsumerThread"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Revoke previously assigned partitions capital-capital-status-update-retry-0","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Member consumer-retryGroup-capital-status-update-2-fc3e75ad-a0c1-446d-8a18-84ba606936d1 sending LeaveGroup request to coordinator localhost:9093 (id: 2147482646 rack: null) due to the consumer is being closed","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Resetting generation and member id due to: consumer pro-actively leaving the group","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"[Consumer clientId=consumer-retryGroup-capital-status-update-2, groupId=retryGroup-capital-status-update] Request joining group due to: consumer pro-actively leaving the group","className":"org.apache.kafka.clients.consumer.internals.ConsumerCoordinator"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"Metrics scheduler closed","className":"org.apache.kafka.common.metrics.Metrics"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"Closing reporter org.apache.kafka.common.metrics.JmxReporter","className":"org.apache.kafka.common.metrics.Metrics"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"Metrics reporters closed","className":"org.apache.kafka.common.metrics.Metrics"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"App info kafka.consumer for consumer-retryGroup-capital-status-update-2 unregistered","className":"org.apache.kafka.common.utils.AppInfoParser"}
{"timestamp":"2025-02-06 09:33:33","level":"DEBUG","message":"delete from kafka_jpa_lock where lock_id=?","className":"org.hibernate.SQL"}
{"timestamp":"2025-02-06 09:33:33","level":"INFO","message":"[retry-consumer-thread-capital-status-update-0-1738834383623] Consumer thread finished","className":"com.omunify.kafka.consumer.thread.RetryConsumerThread"}
